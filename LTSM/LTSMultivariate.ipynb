{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install the necessary libraries\n",
        "!pip install keras-tuner\n",
        "\n",
        "# Step 2: Import the necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "import kerastuner as kt\n",
        "\n",
        "# Load the data\n",
        "file_path = '3Data.xls'  # Update this if your file path is different\n",
        "data = pd.read_excel(file_path)\n",
        "\n",
        "# Inspect the data\n",
        "print(data.head())\n",
        "print(data.columns)\n",
        "\n",
        "# Check for the date column and set it as index if it exists\n",
        "if 'Date' in data.columns:\n",
        "    data['Date'] = pd.to_datetime(data['Date'])\n",
        "    data.set_index('Date', inplace=True)\n",
        "else:\n",
        "    raise ValueError(\"No 'Date' column found. Please provide a correct dataset with a 'Date' column.\")\n",
        "\n",
        "# Subset the data to include 'CPI', 'GSCPI', and 'UNRATE'\n",
        "data = data[['CPI', 'GSCPI', 'UNRATE']]\n",
        "\n",
        "# Split the data into training and test sets (last 12 values)\n",
        "df_train = data[:-12]\n",
        "df_test = data[-12:]\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler()\n",
        "df_train_scaled = scaler.fit_transform(df_train)\n",
        "df_test_scaled = scaler.transform(df_test)\n",
        "\n",
        "# Prepare the data for the LSTM model\n",
        "def create_dataset(X, y, time_steps=1):\n",
        "    Xs, ys = [], []\n",
        "    for i in range(len(X) - time_steps):\n",
        "        v = X[i:(i + time_steps)]\n",
        "        Xs.append(v)\n",
        "        ys.append(y[i + time_steps])\n",
        "    return np.array(Xs), np.array(ys)\n",
        "\n",
        "TIME_STEPS = 12\n",
        "\n",
        "X_train, y_train = create_dataset(df_train_scaled, df_train_scaled[:, 0], TIME_STEPS)\n",
        "\n",
        "# Note: We need to include enough data in the test set to create sequences\n",
        "extended_test = np.concatenate([df_train_scaled[-TIME_STEPS:], df_test_scaled])\n",
        "X_test, y_test = create_dataset(extended_test, extended_test[:, 0], TIME_STEPS)\n",
        "\n",
        "# Define the model building function for Keras Tuner\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=hp.Int('units_1', min_value=32, max_value=512, step=32),\n",
        "                   return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "    model.add(LSTM(units=hp.Int('units_2', min_value=32, max_value=512, step=32),\n",
        "                   return_sequences=False))\n",
        "    model.add(Dense(units=1))\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp.Choice('learning_rate',\n",
        "                                                                             values=[1e-2, 1e-3, 1e-4])),\n",
        "                  loss='mean_squared_error')\n",
        "    return model\n",
        "\n",
        "# Set up the Keras Tuner\n",
        "tuner = kt.RandomSearch(build_model,\n",
        "                        objective='val_loss',\n",
        "                        max_trials=3,\n",
        "                        executions_per_trial=3,\n",
        "                        directory='tuner_dir',\n",
        "                        project_name='cpi_forecast')\n",
        "\n",
        "# Run the tuner to find the best model\n",
        "tuner.search(X_train, y_train, epochs=50, validation_split=0.2)\n",
        "\n",
        "# Get the best model\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "# Train the best model\n",
        "history = best_model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, shuffle=False)\n",
        "\n",
        "# Predict the values\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Reverse scaling\n",
        "y_test_inverse = scaler.inverse_transform(extended_test[TIME_STEPS:])[:, 0]\n",
        "y_pred_inverse = scaler.inverse_transform(np.concatenate((y_pred, extended_test[TIME_STEPS:, 1:]), axis=1))[:, 0]\n",
        "\n",
        "# Combine the actual and forecasted values for comparison\n",
        "combined_df = pd.concat([data, pd.DataFrame(y_pred_inverse, index=df_test.index, columns=['Predicted CPI'])], axis=1)\n",
        "\n",
        "# Forecast next 6 months (including May and June 2024)\n",
        "n_future = 6\n",
        "forecast = []\n",
        "\n",
        "input_seq = extended_test[-TIME_STEPS:]\n",
        "\n",
        "for _ in range(n_future):\n",
        "    input_seq = input_seq.reshape((1, TIME_STEPS, 3))\n",
        "    pred = best_model.predict(input_seq)\n",
        "    forecast.append(pred[0])\n",
        "    # Use zeros for the other features\n",
        "    new_pred = np.concatenate([pred.reshape((1, 1)), np.zeros((1, 2))], axis=1)\n",
        "    input_seq = np.append(input_seq[:, 1:, :], new_pred.reshape((1, 1, 3)), axis=1)\n",
        "\n",
        "forecast = np.array(forecast)\n",
        "forecast_inverse = scaler.inverse_transform(np.concatenate((forecast, np.zeros((n_future, 2))), axis=1))[:, 0]\n",
        "\n",
        "# Combine the forecasted values\n",
        "forecast_dates = pd.date_range(start=df_test.index[-1], periods=n_future + 1, freq='M')[1:]\n",
        "forecast_df = pd.DataFrame(forecast_inverse, index=forecast_dates, columns=['Forecasted CPI'])\n",
        "\n",
        "# Ensure a seamless transition by combining the last predicted value with the first forecasted value\n",
        "combined_df.loc[forecast_dates[0], 'Predicted CPI'] = combined_df['Predicted CPI'].iloc[-1]\n",
        "combined_df = pd.concat([combined_df, forecast_df])\n",
        "\n",
        "# Plot the combined results for the last 18 months (12 test + 6 forecast)\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(combined_df.index[-18:], combined_df['CPI'][-18:], label='Actual CPI')\n",
        "plt.plot(combined_df.index[-18:], combined_df['Predicted CPI'][-18:], label='Predicted CPI')\n",
        "plt.plot(combined_df.index[-18:], combined_df['Forecasted CPI'][-18:], label='Forecasted CPI', linestyle='--')\n",
        "plt.legend()\n",
        "plt.title('CPI (Inflation) Forecast with Next 6 Months Prediction')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('CPI')\n",
        "plt.show()\n",
        "\n",
        "# Display the forecast table\n",
        "forecast_table = combined_df[['CPI', 'Predicted CPI', 'Forecasted CPI']].tail(18)\n",
        "print(forecast_table)\n"
      ],
      "metadata": {
        "id": "V1pPGDooJBim"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}